{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "302175b65d214b0283a038b250bcd0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb393600b50045b5b8441fdc24b07e8e",
              "IPY_MODEL_1e7249ba6e6f427da8babbec2c27bd74",
              "IPY_MODEL_b75de322d4114e0ab7b2670af638eb62"
            ],
            "layout": "IPY_MODEL_f00173be7a3f49f8a3b4730872081cb6",
            "tabbable": null,
            "tooltip": null
          }
        },
        "eb393600b50045b5b8441fdc24b07e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_674ce2b0a1ab445f93020004c9862740",
            "placeholder": "​",
            "style": "IPY_MODEL_e5c3e648db8f4bf8b4b1f9e0589de9d4",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "1e7249ba6e6f427da8babbec2c27bd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b59d054383bf49619dce824f4253448c",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84af3eb5ed4b4d15bafb1e1bfc02e5cb",
            "tabbable": null,
            "tooltip": null,
            "value": 21
          }
        },
        "b75de322d4114e0ab7b2670af638eb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6dcfa5bdc4084116bfbffe2cd9305878",
            "placeholder": "​",
            "style": "IPY_MODEL_396e6c156f4b4452aade0838208a4a65",
            "tabbable": null,
            "tooltip": null,
            "value": " 21/21 [00:00&lt;00:00, 1371.67it/s]"
          }
        },
        "f00173be7a3f49f8a3b4730872081cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674ce2b0a1ab445f93020004c9862740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c3e648db8f4bf8b4b1f9e0589de9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b59d054383bf49619dce824f4253448c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84af3eb5ed4b4d15bafb1e1bfc02e5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dcfa5bdc4084116bfbffe2cd9305878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396e6c156f4b4452aade0838208a4a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting to grips with The LangChain Benchmarks\n",
        "\n",
        "LangChain Benchmarks is a package to help benchmark various LLM related tasks.\n",
        "\n",
        "Docs: https://langchain-ai.github.io/langchain-benchmarks/index.html\n",
        "\n",
        "From the intro page:\n",
        ">The benchmarks are organized by end-to-end use cases, and utilize LangSmith heavily.\n",
        "\n",
        ">We have several goals in open sourcing this:\n",
        "\n",
        "> - Showing how we collect our benchmark datasets for each task.\n",
        "> - Showing what the benchmark datasets we use for each task is.\n",
        "> - Showing how we evaluate each task.\n",
        "> - Encouraging others to benchmark their solutions on these tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "w6mmRN1TyGEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1 Installs, imports and stuff\n"
      ],
      "metadata": {
        "id": "4-I1k4Ok1y5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgvuxPCoyCMd",
        "outputId": "39da2976-13af-4aa8-ea48-b43e76f50a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/72.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U --quiet langchain_benchmarks langchain langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import importlib.metadata\n",
        "    for module in [\"pydantic\", \"langchain\", \"langchain_benchmarks\"]:\n",
        "        try:\n",
        "            print(f\"{module} version: {importlib.metadata.version(module)}\")\n",
        "        except importlib.metadata.PackageNotFoundError:\n",
        "            print(\"{module} is not installed.\")\n",
        "except ImportError:\n",
        "    print(\"importlib.metadata is not available. Try running in python 3.8 or higher.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhDfI97-Vphx",
        "outputId": "4dbae652-12d9-4252-d0f2-372dde32af02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pydantic version: 2.10.6\n",
            "langchain version: 0.2.17\n",
            "langchain_benchmarks version: 0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")"
      ],
      "metadata": {
        "id": "Mx-AQFnd0MtP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 The benchmark\n"
      ],
      "metadata": {
        "id": "lVqKegqw019Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1 The tasks\n",
        "\n",
        "Each benchmark task has a corresponding description, dataset, and other \"environment\" information. You can view the available tasks by checking the registry."
      ],
      "metadata": {
        "id": "8lWL_56f1-vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_benchmarks import registry\n",
        "\n",
        "registry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "QPsZgxul00zc",
        "outputId": "178c69ce-9537-4395-807a-c06da4859546"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Registry(tasks=[ToolUsageTask(name='Tool Usage - Typewriter (1 tool)', dataset_id='https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d', description=\"Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\\n\\nThe objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7feeff984180>, instructions=\"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \", eval_params={'output_evaluation': 'none'}), ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7feeff984680>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\", eval_params={'output_evaluation': 'none'}), ToolUsageTask(name='Tool Usage - Relational Data', dataset_id='https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d', description='Environment with fake data about users and their locations and favorite foods.\\n\\nThe environment provides a set of tools that can be used to query the data.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\\n\\nThe dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\\n\\nEach example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\\n\\nSuccess is measured by the ability to answer the question correctly, and efficiently.\\n', create_environment=<function get_environment at 0x7feeff95fc40>, instructions=\"Please answer the user's question by using the tools provided. Do not guess the answer. Keep in mind that entities like users,foods and locations have both a name and an ID, which are not the same.\", eval_params={}), ToolUsageTask(name='Multiverse Math', dataset_id='https://smith.langchain.com/public/47ed57bc-e852-4f84-a23e-cce4793864e9/d', description='An environment that contains a few basic math operations, but with altered results.\\n\\nFor example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\\n\\nThis task is associated with 20 test examples.\\n', create_environment=<function get_environment at 0x7feeff95f4c0>, instructions='You are requested to solve math questions in an alternate mathematical universe. The operations have been altered to yield different results than expected. Do not guess the answer or rely on your  innate knowledge of math. Use the provided tools to answer the question. While associativity and commutativity apply, distributivity does not. Answer the question using the fewest possible tools. Only include the numeric response without any clarifications.', eval_params={'output_evaluation': 'qa_math_without_question'}), ExtractionTask(name='Email Extraction', dataset_id='https://smith.langchain.com/public/a1742786-bde5-4f51-a1d8-e148e5251ddb/d', description='A dataset of 42 real emails deduped from a spam folder, with semantic HTML tags removed, as well as a script for initial extraction and formatting of other emails from an arbitrary .mbox file like the one exported by Gmail.\\n\\nSome additional cleanup of the data was done by hand after the initial pass.\\n\\nSee https://github.com/jacoblee93/oss-model-extraction-evals.\\n    ', schema=<class 'langchain_benchmarks.extraction.tasks.email_task.Email'>, instructions=ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert researcher.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='What can you tell me about the following email? Make sure to extract the question in the correct format. Here is the email:\\n ```\\n{input}\\n```'))]), dataset_url=None, dataset_name=None, eval_config=None), ExtractionTask(name='Chat Extraction', dataset_id='https://smith.langchain.com/public/00f4444c-9460-4a82-b87a-f50096f1cfef/d', description='A dataset meant to test the ability of an LLM to extract and infer\\nstructured information from a dialogue. The dialogue is between a user and a support\\nengineer. Outputs should be structured as a JSON object and test both the ability\\nof the LLM to correctly structure the information and its ability to perform simple \\nclassification tasks.', schema=<class 'langchain_benchmarks.extraction.tasks.chat_extraction.schema.GenerateTicket'>, instructions=ChatPromptTemplate(input_variables=['dialogue'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpdesk assistant responsible with extracting information and generating tickets. Dialogues are between a user and a support engineer.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dialogue'], template='Generate a ticket for the following question-response pair:\\n<Dialogue>\\n{dialogue}\\n</Dialogue>'))]), dataset_url=None, dataset_name=None, eval_config=None), RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_cached_docs at 0x7fef013ee660>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x7fef00111f80>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x7fef00112020>, 'hyde': <function _chroma_hyde_retriever_factory at 0x7fef001120c0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x7fef013eeac0>}), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", get_docs=<function load_docs at 0x7fef00112d40>, retriever_factories={'basic': <function _chroma_retriever_factory at 0x7fef00112de0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x7fef00112e80>, 'hyde': <function _chroma_hyde_retriever_factory at 0x7fef00112f20>}, architecture_factories={}), RetrievalTask(name='Multi-modal slide decks', dataset_id='https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d', description='This public dataset is a work-in-progress and will be extended over time.\\n        \\nQuestions and answers based on slide decks containing visual tables and charts.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\n', get_docs={}, retriever_factories={}, architecture_factories={}), ExtractionTask(name='Name Correction', dataset_id='https://smith.langchain.com/public/78df83ee-ba7f-41c6-832c-2b23327d4cf7/d', description='A dataset of 23 misspelled full names and their correct spellings.', schema=<class 'langchain_benchmarks.extraction.tasks.high_cardinality.name_correction.Person'>, instructions=None, dataset_url='https://smith.langchain.com/public/78df83ee-ba7f-41c6-832c-2b23327d4cf7/d', dataset_name='Extracting Corrected Names', eval_config=RunEvalConfig(evaluators=[], custom_evaluators=[<DynamicRunEvaluator correct_name>], batch_evaluators=None, reference_key=None, prediction_key=None, input_key=None, eval_llm=None))])"
            ],
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>Name                              </th><th>Type          </th><th>Dataset ID                                                                                                                                                 </th><th>Description                                                       </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>Tool Usage - Typewriter (1 tool)  </td><td>ToolUsageTask </td><td><a href=\"https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d\" target=\"_blank\" rel=\"noopener\">59577193-8938-4ccf-92a7-e8a96bcf4f86</a></td><td>Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\n",
              "\n",
              "The objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\n",
              "\n",
              "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
              "\n",
              "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.                                                                   </td></tr>\n",
              "<tr><td>Tool Usage - Typewriter (26 tools)</td><td>ToolUsageTask </td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
              "\n",
              "The objective of this task is to evaluate the model's ability the use tools\n",
              "for a simple repetition task.\n",
              "\n",
              "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
              "\n",
              "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
              "\n",
              "This is a variation of the typer writer task, where 26 parameterless tools are\n",
              "given instead of a single tool that takes a letter as an argument.                                                                   </td></tr>\n",
              "<tr><td>Tool Usage - Relational Data      </td><td>ToolUsageTask </td><td><a href=\"https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d\" target=\"_blank\" rel=\"noopener\">1d89f4b3-5f73-48cf-a127-2fdeb22f6d84</a></td><td>Environment with fake data about users and their locations and favorite foods.\n",
              "\n",
              "The environment provides a set of tools that can be used to query the data.\n",
              "\n",
              "The objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\n",
              "\n",
              "The dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\n",
              "\n",
              "Each example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\n",
              "\n",
              "Success is measured by the ability to answer the question correctly, and efficiently.                                                                   </td></tr>\n",
              "<tr><td>Multiverse Math                   </td><td>ToolUsageTask </td><td><a href=\"https://smith.langchain.com/public/47ed57bc-e852-4f84-a23e-cce4793864e9/d\" target=\"_blank\" rel=\"noopener\">47ed57bc-e852-4f84-a23e-cce4793864e9</a></td><td>An environment that contains a few basic math operations, but with altered results.\n",
              "\n",
              "For example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\n",
              "\n",
              "The objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\n",
              "\n",
              "This task is associated with 20 test examples.                                                                   </td></tr>\n",
              "<tr><td>Email Extraction                  </td><td>ExtractionTask</td><td><a href=\"https://smith.langchain.com/public/a1742786-bde5-4f51-a1d8-e148e5251ddb/d\" target=\"_blank\" rel=\"noopener\">a1742786-bde5-4f51-a1d8-e148e5251ddb</a></td><td>A dataset of 42 real emails deduped from a spam folder, with semantic HTML tags removed, as well as a script for initial extraction and formatting of other emails from an arbitrary .mbox file like the one exported by Gmail.\n",
              "\n",
              "Some additional cleanup of the data was done by hand after the initial pass.\n",
              "\n",
              "See https://github.com/jacoblee93/oss-model-extraction-evals.                                                                   </td></tr>\n",
              "<tr><td>Chat Extraction                   </td><td>ExtractionTask</td><td><a href=\"https://smith.langchain.com/public/00f4444c-9460-4a82-b87a-f50096f1cfef/d\" target=\"_blank\" rel=\"noopener\">00f4444c-9460-4a82-b87a-f50096f1cfef</a></td><td>A dataset meant to test the ability of an LLM to extract and infer\n",
              "structured information from a dialogue. The dialogue is between a user and a support\n",
              "engineer. Outputs should be structured as a JSON object and test both the ability\n",
              "of the LLM to correctly structure the information and its ability to perform simple \n",
              "classification tasks.                                                                   </td></tr>\n",
              "<tr><td>LangChain Docs Q&A                </td><td>RetrievalTask </td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
              "\n",
              "The environment provides the documents and the retriever information.\n",
              "\n",
              "Each example is composed of a question and reference answer.\n",
              "\n",
              "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
              "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                   </td></tr>\n",
              "<tr><td>Semi-structured Reports           </td><td>RetrievalTask </td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n",
              "\n",
              "The task provides the raw documents as well as factory methods to easily index them\n",
              "and create a retriever.\n",
              "\n",
              "Each example is composed of a question and reference answer.\n",
              "\n",
              "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
              "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                   </td></tr>\n",
              "<tr><td>Multi-modal slide decks           </td><td>RetrievalTask </td><td><a href=\"https://smith.langchain.com/public/40afc8e7-9d7e-44ed-8971-2cae1eb59731/d\" target=\"_blank\" rel=\"noopener\">40afc8e7-9d7e-44ed-8971-2cae1eb59731</a></td><td>This public dataset is a work-in-progress and will be extended over time.\n",
              "        \n",
              "Questions and answers based on slide decks containing visual tables and charts.\n",
              "\n",
              "Each example is composed of a question and reference answer.\n",
              "\n",
              "Success is measured based on the accuracy of the answer relative to the reference answer.                                                                   </td></tr>\n",
              "<tr><td>Name Correction                   </td><td>ExtractionTask</td><td><a href=\"https://smith.langchain.com/public/78df83ee-ba7f-41c6-832c-2b23327d4cf7/d\" target=\"_blank\" rel=\"noopener\">78df83ee-ba7f-41c6-832c-2b23327d4cf7</a></td><td>A dataset of 23 misspelled full names and their correct spellings.</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Downloading datasets\n",
        "\n",
        "Each benchmark task has a corresponding dataset. To run evals on the specified benchmark, you can use our download function. For more details on working with datasets within the LangChain Benchmarks package, check out the [datasets notebook](https://langchain-ai.github.io/langchain-benchmarks/notebooks/datasets.html).\n",
        "\n",
        "See also https://langchain-ai.github.io/langchain-benchmarks/notebooks/datasets.html\n",
        "\n",
        "Note the difference between clone and download:\n",
        "- **clone_public_dataset** will clone the dataset to your own LangSmith tenant\n",
        "- **download_public_dataset** will download it to the local file system\n"
      ],
      "metadata": {
        "id": "N-cO1zfJ1yDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_benchmarks import clone_public_dataset, download_public_dataset"
      ],
      "metadata": {
        "id": "dCHKV2Q60t_2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(download_public_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmx2QjHD4Mfa",
        "outputId": "800c2031-f95a-4e8c-ad5a-1c5f04a64af6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function download_public_dataset in module langchain_benchmarks.utils._langsmith:\n",
            "\n",
            "download_public_dataset(token_or_url: str, *, path: Union[str, pathlib.Path, NoneType] = None, api_url: str = 'https://api.smith.langchain.com/') -> None\n",
            "    Download a public dataset.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = registry[\"Tool Usage - Relational Data\"]"
      ],
      "metadata": {
        "id": "duNEv3kq4IQH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#clone_public_dataset(task.dataset_id)"
      ],
      "metadata": {
        "id": "4yvcR6fUIkR8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_public_dataset(task.dataset_id, path=\"tool_usage_relational_data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "302175b65d214b0283a038b250bcd0f7",
            "eb393600b50045b5b8441fdc24b07e8e",
            "1e7249ba6e6f427da8babbec2c27bd74",
            "b75de322d4114e0ab7b2670af638eb62",
            "f00173be7a3f49f8a3b4730872081cb6",
            "674ce2b0a1ab445f93020004c9862740",
            "e5c3e648db8f4bf8b4b1f9e0589de9d4",
            "b59d054383bf49619dce824f4253448c",
            "84af3eb5ed4b4d15bafb1e1bfc02e5cb",
            "6dcfa5bdc4084116bfbffe2cd9305878",
            "396e6c156f4b4452aade0838208a4a65"
          ]
        },
        "id": "Axc3Y4ry4ZD4",
        "outputId": "9bc473fa-6547-4f0d-f76f-9e4c30608a6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching examples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "302175b65d214b0283a038b250bcd0f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fetching examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBMnu0E_4nN9",
        "outputId": "de7aa66c-172e-49bf-d5e1-8c3a8d227d2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28\n",
            "drwxr-xr-x 1 root root  4096 Mar  6 02:54 .\n",
            "drwxr-xr-x 1 root root  4096 Mar  6 02:42 ..\n",
            "drwxr-xr-x 4 root root  4096 Mar  4 14:26 .config\n",
            "drwxr-xr-x 1 root root  4096 Mar  4 14:26 sample_data\n",
            "-rw-r--r-- 1 root root 11857 Mar  6 02:54 tool_usage_relational_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading it to my local machine..."
      ],
      "metadata": {
        "id": "JbKyIS_9mBBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"tool_usage_relational_data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Igmn87nhmEJ_",
        "outputId": "99630689-eae0-463f-eacb-a8d9849abf88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36e32f15-7949-49da-a7e8-a13e04caf462\", \"tool_usage_relational_data.json\", 11857)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Looking at the data\n",
        "\n",
        "We'll start by looking at one of the benchmark tasks -- [Tool Usage - Relational Data](https://langchain-ai.github.io/langchain-benchmarks/notebooks/tool_usage/relational_data.html).\n",
        "\n",
        "In this task, an agent is given access to a set of tools that can be used to make queries across 3 relational tables.\n",
        "\n",
        "The tables contain information about users, locations and foods. The agent must answer questions about the data using the provided tools."
      ],
      "metadata": {
        "id": "BYaYE32N-phs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"tool_usage_relational_data.json\", \"r\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "iDPuqy7V6Ful"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0])\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPlGFvstCLX9",
        "outputId": "a0c1c9d5-25e5-42c2-c653-ad3c0fda5fcc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset_id': 'df6be6c9-05b3-445e-8836-ebb4aba63826', 'inputs': {'question': 'What is the city for location ID 1?'}, 'outputs': {'reference': 'New York', 'order_matters': True, 'expected_steps': ['get_city_for_location']}, 'metadata': None, 'id': '114cb5ab-3ffb-4ac0-b4f8-3b7cd7baf58f', 'created_at': '2023-11-18T00:30:11.557683+00:00', 'modified_at': '2023-11-18T00:30:11.557683+00:00', 'runs': [], 'source_run_id': None}\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in data[0].items():\n",
        "    print(k, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI-TWke1MtTQ",
        "outputId": "22724842-accb-4eb7-ac74-737980acf059"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_id df6be6c9-05b3-445e-8836-ebb4aba63826\n",
            "inputs {'question': 'What is the city for location ID 1?'}\n",
            "outputs {'reference': 'New York', 'order_matters': True, 'expected_steps': ['get_city_for_location']}\n",
            "metadata None\n",
            "id 114cb5ab-3ffb-4ac0-b4f8-3b7cd7baf58f\n",
            "created_at 2023-11-18T00:30:11.557683+00:00\n",
            "modified_at 2023-11-18T00:30:11.557683+00:00\n",
            "runs []\n",
            "source_run_id None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in enumerate(data):\n",
        "    print(row[\"inputs\"][\"question\"])\n",
        "    print(f\"  {row['outputs']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AnSY6zZ-4eM",
        "outputId": "a92eb987-68c2-46df-b720-ddfa0e637125"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the city for location ID 1?\n",
            "  {'reference': 'New York', 'order_matters': True, 'expected_steps': ['get_city_for_location']}\n",
            "What is the name of food with id 6?\n",
            "  {'reference': 'Pasta', 'order_matters': True, 'expected_steps': ['get_food_name']}\n",
            "what is eve's user id?\n",
            "  {'reference': '42', 'order_matters': True, 'expected_steps': ['find_users_by_name']}\n",
            "get the current user id\n",
            "  {'reference': '35', 'order_matters': True, 'expected_steps': ['get_current_user_id']}\n",
            "How many users by the name of bob?\n",
            "  {'reference': '1', 'order_matters': True, 'expected_steps': ['find_users_by_name']}\n",
            "what is alice's email address?\n",
            "  {'reference': 'alice@gmail.com', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_email']}\n",
            "find donna's favorite color\n",
            "  {'reference': 'green', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_favorite_color']}\n",
            "weather in LA right now?\n",
            "  {'reference': 'Sunny, Temperature: 75°F', 'order_matters': True, 'expected_steps': ['find_locations_by_name', 'get_current_weather_for_location']}\n",
            "time in chicago\n",
            "  {'reference': '2023-11-14 11:15 AM', 'order_matters': True, 'expected_steps': ['find_locations_by_name', 'get_current_time_for_location']}\n",
            "list the allergens in chocolate\n",
            "  {'reference': 'milk, soy', 'order_matters': True, 'expected_steps': ['find_foods_by_name', 'get_food_allergic_ingredients']}\n",
            "If i eat a serving of pizza, how many calories will I consume?\n",
            "  {'reference': '285 calories', 'order_matters': True, 'expected_steps': ['find_foods_by_name', 'get_food_calories']}\n",
            "what is the current users favorite color?\n",
            "  {'reference': 'yellow', 'order_matters': True, 'expected_steps': ['get_current_user_id', 'get_user_favorite_color']}\n",
            "eve ate a serving of sushi, what allergens was she exposed to?\n",
            "  {'reference': 'fish, soy', 'order_matters': True, 'expected_steps': ['find_foods_by_name', 'get_food_allergic_ingredients']}\n",
            "Frank who is Even's friend is allergic to dairy. Can he eat the salad?\n",
            "  {'reference': 'yes', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_food_allergic_ingredients']}\n",
            "what is the current users favorite color and name?\n",
            "  {'reference': 'yellow and Charlie', 'order_matters': True, 'expected_steps': ['get_current_user_id', 'get_user_favorite_color', 'get_user_name']}\n",
            "whats the name of the city where bob lives?\n",
            "  {'reference': 'Los Angeles', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_location', 'get_city_for_location']}\n",
            "Donna is about to go outside. Does she need an umbrella?\n",
            "  {'reference': 'yes', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_location', 'get_current_weather_for_location']}\n",
            "Is it likely that Donna is awake right now?\n",
            "  {'reference': 'yes', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_location', 'get_current_time_for_location']}\n",
            "do alice and charlie use the same email provider?\n",
            "  {'reference': 'no', 'order_matters': True, 'expected_steps': ['find_users_by_name', 'get_user_email', 'get_user_email']}\n",
            "Is it likely that Donna is outside with an umbrella at this time?\n",
            "  {'reference': 'yes', 'order_matters': False, 'expected_steps': ['find_users_by_name', 'get_user_location', 'get_current_time_for_location', 'get_current_weather_for_location']}\n",
            "do bob and alice live in the same city?\n",
            "  {'reference': 'no', 'order_matters': False, 'expected_steps': ['find_users_by_name', 'get_user_location', 'get_city_for_location', 'get_user_location', 'get_city_for_location']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 The model registry\n",
        "\n",
        "LangChain Benchmark also includes a model registry to make it easier to run benchmarks across different models.\n",
        "\n",
        "We'll get back to that later, but see https://langchain-ai.github.io/langchain-benchmarks/notebooks/models.html for introduction.\n",
        "\n"
      ],
      "metadata": {
        "id": "vGbqbMxYM-TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 The task environment\n",
        "\n",
        "The task environment contains the tools and the data to run the experiments."
      ],
      "metadata": {
        "id": "-I3yfspHGYaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = task.create_environment()\n",
        "#dir(env)"
      ],
      "metadata": {
        "id": "lTaQCAOM-5vr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tool in env.tools:\n",
        "    print(tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsF9OxeZGvfV",
        "outputId": "a0b8fbfc-9969-422a-f2e9-2fa09eeaf3f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='get_user_name' description=\"Get the name of the user with the given user ID.\\n\\n        Args:\\n            user_id: The user's ID.\\n\\n        Returns:\\n            The user's name.\" args_schema=<class 'pydantic.v1.main.get_user_nameSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_user_name at 0x7feeff9e19e0>\n",
            "name='list_user_ids' description='List all the user IDs.' args_schema=<class 'pydantic.v1.main.list_user_idsSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.list_user_ids at 0x7feeff9e1940>\n",
            "name='find_users_by_name' description='Find users with the given name.\\n\\n        Args:\\n            name: The name to search for.\\n\\n        Returns:\\n            The list of matching users.' args_schema=<class 'pydantic.v1.main.find_users_by_nameSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.find_users_by_name at 0x7feeff9e2160>\n",
            "name='find_locations_by_name' description='Find locations with the given city name.' args_schema=<class 'pydantic.v1.main.find_locations_by_nameSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.find_locations_by_name at 0x7feeff9e1c60>\n",
            "name='find_foods_by_name' description='Find foods with the given name.' args_schema=<class 'pydantic.v1.main.find_foods_by_nameSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.find_foods_by_name at 0x7feeff9e2020>\n",
            "name='get_user_email' description=\"Get the email of the user with the given user ID.\\n\\n        Args:\\n            user_id: The user's ID.\\n\\n        Returns:\\n            The user's email.\" args_schema=<class 'pydantic.v1.main.get_user_emailSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_user_email at 0x7feeff9e1a80>\n",
            "name='get_user_location' description=\"Get the location ID of the user with the given user ID.\\n\\n        Args:\\n            user_id: The user's ID.\\n\\n        Returns:\\n            The user's location ID.\" args_schema=<class 'pydantic.v1.main.get_user_locationSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_user_location at 0x7feeff9e2200>\n",
            "name='get_user_favorite_color' description=\"Get the favorite color of the user with the given user ID.\\n\\n        Args:\\n            user_id: The user's ID.\\n\\n        Returns:\\n            The user's favorite color.\" args_schema=<class 'pydantic.v1.main.get_user_favorite_colorSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_user_favorite_color at 0x7feeff9e22a0>\n",
            "name='get_user_favorite_foods' description=\"Get the list of favorite foods of the user with the given user ID.\\n\\n        Args:\\n            user_id: The user's ID.\\n\\n        Returns:\\n            The list of favorite foods.\" args_schema=<class 'pydantic.v1.main.get_user_favorite_foodsSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_user_favorite_foods at 0x7feeff9e2340>\n",
            "name='get_weather_at_location' description=\"Get the current weather at the location with the given location ID.\\n\\n        Args:\\n            location_id: The location's ID.\\n\\n        Returns:\\n            The current weather at the location.\" args_schema=<class 'pydantic.v1.main.get_weather_at_locationSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_weather_at_location at 0x7feeff9e23e0>\n",
            "name='get_city_for_location' description=\"Get the city for the location with the given location ID.\\n\\n        Args:\\n            location_id: The location's ID.\\n\\n        Returns:\\n            The city name for the location.\" args_schema=<class 'pydantic.v1.main.get_city_for_locationSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_city_for_location at 0x7feeff9e2480>\n",
            "name='get_current_time_for_location' description=\"Get the current time for the location with the given location ID.\\n\\n        Args:\\n            location_id: The location's ID.\\n\\n        Returns:\\n            The current time for the location.\" args_schema=<class 'pydantic.v1.main.get_current_time_for_locationSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_current_time_for_location at 0x7feeff9e2520>\n",
            "name='get_current_weather_for_location' description=\"Get the current weather for the location with the given location ID.\\n\\n        Args:\\n            location_id: The location's ID.\\n\\n        Returns:\\n            The current weather for the location.\" args_schema=<class 'pydantic.v1.main.get_current_weather_for_locationSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_current_weather_for_location at 0x7feeff9e25c0>\n",
            "name='get_food_name' description=\"Get the name of the food with the given food ID.\\n\\n        Args:\\n            food_id: The food's ID.\\n\\n        Returns:\\n            The name of the food.\" args_schema=<class 'pydantic.v1.main.get_food_nameSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_food_name at 0x7feeff9e2660>\n",
            "name='get_food_calories' description=\"Get the calories per serving for the food with the given food ID.\\n\\n        Args:\\n            food_id: The food's ID.\\n\\n        Returns:\\n            The calories per serving of the food.\" args_schema=<class 'pydantic.v1.main.get_food_caloriesSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_food_calories at 0x7feeff9e2700>\n",
            "name='get_food_allergic_ingredients' description=\"Get the list of allergic ingredients for the food with the given food ID.\\n\\n        Args:\\n            food_id: The food's ID.\\n\\n        Returns:\\n            The list of allergic ingredients.\" args_schema=<class 'pydantic.v1.main.get_food_allergic_ingredientsSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_food_allergic_ingredients at 0x7feeff9e27a0>\n",
            "name='get_current_user_id' description=\"Get the current user's ID.\\n\\n        Returns:\\n            The current user's ID.\" args_schema=<class 'pydantic.v1.main.get_current_user_idSchema'> handle_tool_error=True func=<function get_available_functions.<locals>.get_current_user_id at 0x7feeff9e2840>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tools allow to look up information based on ids (e.g., get_user_email takes a user id and returns the email), and to search (e.g., find_foods_by_name takes a food name and returns a list of results).\n"
      ],
      "metadata": {
        "id": "rNr7VZoOPOwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.tools[0].invoke({\"user_id\": 21})"
      ],
      "metadata": {
        "id": "t8-vfHG7IAc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a3fdbaf5-eb4f-4024-91f6-f2f0e141be5d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bob'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.tools[3].invoke({\"city\": \"LA\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKuJrzXbPc-f",
        "outputId": "57491e55-1add-4872-defa-807c62a4c153"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 2, 'city': 'Los Angeles'},\n",
              " {'id': 1, 'city': 'New York'},\n",
              " {'id': 3, 'city': 'Chicago'},\n",
              " {'id': 4, 'city': 'Houston'},\n",
              " {'id': 5, 'city': 'Miami'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This I didn't understand at first, but turns out that...\n",
        "...find_locations_by_name function in https://github.com/langchain-ai/langchain-benchmarks/blob/main/langchain_benchmarks/tool_usage/tasks/relational_data.py\n",
        "\n",
        "returns all locations sorted in descending order by \"jaccard similarity based on the number of shared characters between the query and the data\".\n"
      ],
      "metadata": {
        "id": "2RErusjYQRr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3 Create an agent\n",
        "\n",
        "https://langchain-ai.github.io/langchain-benchmarks/notebooks/tool_usage/intro.html#create-an-agent\n",
        "\n",
        "Because an agent interacts with the environment via tools and can change the state of the environment during the course of an agent run, what we actually want is the ability to create a fresh agent and a fresh environment for each test run.\n",
        "\n",
        "We’ll do this using a factory. A factory is just a fancy name in computer science for an object that can create other objects. In this case, we’ll have an Agent Factory that we can call and it’ll create a fresh agent for us on each call.\n",
        "\n",
        "We’ll use the StandardAgentFactory which under the hood creates a standard LangChain tool calling agent. It can be used with any Chat Model that supports tool calling.\n",
        "\n"
      ],
      "metadata": {
        "id": "DDgDATAj148A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_S2wBRg3Fgt",
        "outputId": "f22f49ea-f47f-421c-a270-1e77e7acc13b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/243.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/243.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/415.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.41 which is incompatible.\n",
            "langchain-community 0.2.19 requires langchain-core<0.3.0,>=0.2.43, but you have langchain-core 0.3.41 which is incompatible.\n",
            "langchain 0.2.17 requires langchain-core<0.3.0,>=0.2.43, but you have langchain-core 0.3.41 which is incompatible.\n",
            "langchain-openai 0.1.25 requires langchain-core<0.3.0,>=0.2.40, but you have langchain-core 0.3.41 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYIs99MOkUm",
        "outputId": "8769e21c-339d-4956-f201-4c3a2ed56f68"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-benchmarks 0.0.14 requires langchain-openai<0.2.0,>=0.1.14, but you have langchain-openai 0.3.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "-A_q_793Oxq_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain_benchmarks.tool_usage.agents import StandardAgentFactory\n",
        "\n",
        "#model = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0)\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"{instructions}\"),  # Populated from task.instructions automatically\n",
        "        (\n",
        "            \"human\",\n",
        "            \"{question}\",\n",
        "        ),  # Each evaluation example is associated with a question\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),  # Space for the agent to do work\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent_factory = StandardAgentFactory(task, model, prompt)"
      ],
      "metadata": {
        "id": "rLo_k-OqS6lV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import globals\n",
        "\n",
        "globals.set_verbose(True)\n",
        "agent = agent_factory()\n",
        "agent.invoke({\"question\": \"what is the weather in LA\"})"
      ],
      "metadata": {
        "id": "n0yC0FLN3dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "2ebd0ecc-2bce-43b2-e561-515d648aca57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "no validator found for <class 'langchain_core.runnables.base.Runnable'>, see `arbitrary_types_allowed` in Config",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-532d5b4fdeac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"what is the weather in LA\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5091\u001b[0m     ) -> AsyncIterator[StreamEvent]:\n\u001b[1;32m   5092\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5093\u001b[0;31m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RunnableEach does not support astream_events yet.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5094\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5095\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2852\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mschema\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2854\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m   2855\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_seq_output_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/beta/runnables/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mContextSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableSerializable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;34m\"\"\"Set a context value.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     ):\n\u001b[1;32m    196\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     fields[ann_name] = ModelField.infer(\n\u001b[0m\u001b[1;32m    198\u001b[0m                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                         \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotation_from_field_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAPE_SINGLETON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m_type_analysis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# type_ has been refined eg. as the type of a List and sub_fields needs to be populated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sub_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_discriminated_union_sub_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m_create_sub_type\u001b[0;34m(self, type_, name, for_keys)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mfield_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         return self.__class__(\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAPE_SINGLETON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefined\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_default_and_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mpopulate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             v_funcs = (\n\u001b[1;32m    828\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_validators_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meach_item\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mget_validators\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_validators_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meach_item\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/validators.py\u001b[0m in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__pydantic_core_schema__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mixing V1 and V2 models is not supported. `{type_.__name__}` is a V2 model.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'no validator found for {type_}, see `arbitrary_types_allowed` in Config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 'langchain_core.runnables.base.Runnable'>, see `arbitrary_types_allowed` in Config"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rbp-feOmQBTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}